{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "196b24ef-4145-4225-bfeb-05f01b638a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.9/site-packages (23.1.2)\n",
      "Collecting tfx[kfp]<2\n",
      "  Downloading tfx-1.13.0-py3-none-any.whl (2.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting ml-pipelines-sdk==1.13.0 (from tfx[kfp]<2)\n",
      "  Downloading ml_pipelines_sdk-1.13.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: absl-py<2.0.0,>=0.9 in /opt/conda/lib/python3.9/site-packages (from tfx[kfp]<2) (0.15.0)\n",
      "Collecting ml-metadata<1.14.0,>=1.13.1 (from tfx[kfp]<2)\n",
      "  Downloading ml_metadata-1.13.1-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting packaging<21,>=20 (from tfx[kfp]<2)\n",
      "  Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting portpicker<2,>=1.3.1 (from tfx[kfp]<2)\n",
      "  Downloading portpicker-1.5.2-py3-none-any.whl (14 kB)\n",
      "Collecting protobuf<5,>=3.20.3 (from tfx[kfp]<2)\n",
      "  Downloading protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting docker<5,>=4.1 (from tfx[kfp]<2)\n",
      "  Downloading docker-4.4.4-py2.py3-none-any.whl (147 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.0/147.0 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: google-apitools<1,>=0.5 in /opt/conda/lib/python3.9/site-packages (from tfx[kfp]<2) (0.5.31)\n",
      "Requirement already satisfied: google-api-python-client<2,>=1.8 in /opt/conda/lib/python3.9/site-packages (from tfx[kfp]<2) (1.8.0)\n",
      "Requirement already satisfied: jinja2<4,>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from tfx[kfp]<2) (3.1.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=3.10.0.2 in /opt/conda/lib/python3.9/site-packages (from tfx[kfp]<2) (3.10.0.2)\n",
      "Requirement already satisfied: apache-beam[gcp]<3,>=2.40 in /opt/conda/lib/python3.9/site-packages (from tfx[kfp]<2) (2.46.0)\n",
      "Collecting attrs<22,>=19.3.0 (from tfx[kfp]<2)\n",
      "  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click<9,>=7 in /opt/conda/lib/python3.9/site-packages (from tfx[kfp]<2) (8.1.3)\n",
      "Collecting google-api-core<1.33 (from tfx[kfp]<2)\n",
      "  Downloading google_api_core-1.32.0-py2.py3-none-any.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.6/93.6 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-cloud-aiplatform<1.18,>=1.6.2 (from tfx[kfp]<2)\n",
      "  Downloading google_cloud_aiplatform-1.17.1-py2.py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-cloud-bigquery<3,>=2.26.0 (from tfx[kfp]<2)\n",
      "  Downloading google_cloud_bigquery-2.34.4-py2.py3-none-any.whl (206 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.6/206.6 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: grpcio<2,>=1.28.1 in /opt/conda/lib/python3.9/site-packages (from tfx[kfp]<2) (1.46.4)\n",
      "Requirement already satisfied: keras-tuner<2,>=1.0.4 in /opt/conda/lib/python3.9/site-packages (from tfx[kfp]<2) (1.3.5)\n",
      "Collecting kubernetes<13,>=10.0.1 (from tfx[kfp]<2)\n",
      "  Downloading kubernetes-12.0.1-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2,>=1.16 in /opt/conda/lib/python3.9/site-packages (from tfx[kfp]<2) (1.19.5)\n",
      "Collecting pyarrow<7,>=6 (from tfx[kfp]<2)\n",
      "  Downloading pyarrow-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.6/25.6 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyyaml<6,>=3.12 (from tfx[kfp]<2)\n",
      "  Downloading PyYAML-5.4.1-cp39-cp39-manylinux1_x86_64.whl (630 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m630.1/630.1 kB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow<2.13,>=2.12.0 (from tfx[kfp]<2)\n",
      "  Downloading tensorflow-2.12.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.9/585.9 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-hub<0.13,>=0.9.0 (from tfx[kfp]<2)\n",
      "  Downloading tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.8/108.8 kB\u001b[0m \u001b[31m257.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-data-validation<1.14.0,>=1.13.0 (from tfx[kfp]<2)\n",
      "  Downloading tensorflow_data_validation-1.13.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-model-analysis<0.45.0,>=0.44.0 (from tfx[kfp]<2)\n",
      "  Downloading tensorflow_model_analysis-0.44.0-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-serving-api!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15 (from tfx[kfp]<2)\n",
      "  Downloading tensorflow_serving_api-2.12.1-py2.py3-none-any.whl (26 kB)\n",
      "Collecting tensorflow-transform<1.14.0,>=1.13.0 (from tfx[kfp]<2)\n",
      "  Downloading tensorflow_transform-1.13.0-py3-none-any.whl (443 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.8/443.8 kB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tfx-bsl<1.14.0,>=1.13.0 (from tfx[kfp]<2)\n",
      "  Downloading tfx_bsl-1.13.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.5/22.5 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting kfp<2,>=1.8.14 (from tfx[kfp]<2)\n",
      "  Downloading kfp-1.8.22.tar.gz (304 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.9/304.9 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting kfp-pipeline-spec<0.2,>=0.1.10 (from tfx[kfp]<2)\n",
      "  Downloading kfp_pipeline_spec-0.1.16-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from absl-py<2.0.0,>=0.9->tfx[kfp]<2) (1.15.0)\n",
      "Collecting protobuf<5,>=3.20.3 (from tfx[kfp]<2)\n",
      "  Downloading protobuf-3.20.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: crcmod<2.0,>=1.7 in /opt/conda/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.40->tfx[kfp]<2) (1.7)\n",
      "Requirement already satisfied: orjson<4.0 in /opt/conda/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.40->tfx[kfp]<2) (3.9.1)\n",
      "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /opt/conda/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.40->tfx[kfp]<2) (0.3.1.1)\n",
      "Requirement already satisfied: cloudpickle~=2.2.1 in /opt/conda/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.40->tfx[kfp]<2) (2.2.1)\n",
      "Requirement already satisfied: fastavro<2,>=0.23.6 in /opt/conda/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.40->tfx[kfp]<2) (1.7.4)\n",
      "Requirement already satisfied: fasteners<1.0,>=0.3 in /opt/conda/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.40->tfx[kfp]<2) (0.18)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /opt/conda/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.40->tfx[kfp]<2) (2.7.0)\n",
      "Requirement already satisfied: httplib2<0.22.0,>=0.8 in /opt/conda/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.40->tfx[kfp]<2) (0.21.0)\n",
      "Requirement already satisfied: objsize<0.7.0,>=0.6.1 in /opt/conda/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.40->tfx[kfp]<2) (0.6.1)\n",
      "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /opt/conda/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.40->tfx[kfp]<2) (3.13.0)\n",
      "Requirement already satisfied: proto-plus<2,>=1.7.1 in /opt/conda/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.40->tfx[kfp]<2) (1.22.2)\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /opt/conda/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.40->tfx[kfp]<2) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /opt/conda/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.40->tfx[kfp]<2) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2018.3 in /opt/conda/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.40->tfx[kfp]<2) (2023.3)\n",
      "Requirement already satisfied: regex>=2020.6.8 in /opt/conda/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.40->tfx[kfp]<2) (2023.6.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /opt/conda/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.40->tfx[kfp]<2) (2.31.0)\n",
      "Requirement already satisfied: zstandard<1,>=0.18.0 in /opt/conda/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.40->tfx[kfp]<2) (0.19.0)\n",
      "Requirement already satisfied: cachetools<5,>=3.1.0 in /opt/conda/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.40->tfx[kfp]<2) (4.2.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.18.0 in /opt/conda/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.40->tfx[kfp]<2) (1.35.0)\n",
      "Requirement already satisfied: google-auth-httplib2<0.2.0,>=0.1.0 in /opt/conda/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.40->tfx[kfp]<2) (0.1.0)\n",
      "Requirement already satisfied: google-cloud-datastore<2,>=1.8.0 in /opt/conda/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.40->tfx[kfp]<2) (1.15.5)\n",
      "Requirement already satisfied: google-cloud-pubsub<3,>=2.1.0 in /opt/conda/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.40->tfx[kfp]<2) (2.17.1)\n",
      "Requirement already satisfied: google-cloud-pubsublite<2,>=1.2.0 in /opt/conda/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.40->tfx[kfp]<2) (1.8.2)\n",
      "Requirement already satisfied: google-cloud-bigquery-storage<2.17,>=2.6.3 in /opt/conda/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.40->tfx[kfp]<2) (2.16.2)\n",
      "Requirement already satisfied: google-cloud-core<3,>=0.28.1 in /opt/conda/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.40->tfx[kfp]<2) (2.3.2)\n",
      "Requirement already satisfied: google-cloud-bigtable<2,>=0.31.1 in /opt/conda/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.40->tfx[kfp]<2) (1.7.3)\n",
      "Requirement already satisfied: google-cloud-spanner<4,>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.40->tfx[kfp]<2) (3.36.0)\n",
      "Requirement already satisfied: google-cloud-dlp<4,>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.40->tfx[kfp]<2) (3.12.1)\n",
      "Requirement already satisfied: google-cloud-language<2,>=1.3.0 in /opt/conda/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.40->tfx[kfp]<2) (1.3.2)\n",
      "Requirement already satisfied: google-cloud-videointelligence<2,>=1.8.0 in /opt/conda/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.40->tfx[kfp]<2) (1.16.3)\n",
      "Requirement already satisfied: google-cloud-vision<4,>=2 in /opt/conda/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.40->tfx[kfp]<2) (3.4.2)\n",
      "Requirement already satisfied: google-cloud-recommendations-ai<0.8.0,>=0.1.0 in /opt/conda/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.40->tfx[kfp]<2) (0.7.1)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /opt/conda/lib/python3.9/site-packages (from docker<5,>=4.1->tfx[kfp]<2) (1.5.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.9/site-packages (from google-api-core<1.33->tfx[kfp]<2) (1.59.1)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.9/site-packages (from google-api-core<1.33->tfx[kfp]<2) (67.7.2)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from google-api-python-client<2,>=1.8->tfx[kfp]<2) (3.0.1)\n",
      "Requirement already satisfied: oauth2client>=1.4.12 in /opt/conda/lib/python3.9/site-packages (from google-apitools<1,>=0.5->tfx[kfp]<2) (4.1.3)\n",
      "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0 in /opt/conda/lib/python3.9/site-packages (from google-cloud-aiplatform<1.18,>=1.6.2->tfx[kfp]<2) (1.34.0)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /opt/conda/lib/python3.9/site-packages (from google-cloud-aiplatform<1.18,>=1.6.2->tfx[kfp]<2) (2.9.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.9/site-packages (from google-cloud-aiplatform<1.18,>=1.6.2->tfx[kfp]<2) (1.10.1)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.9/site-packages (from google-cloud-bigquery<3,>=2.26.0->tfx[kfp]<2) (2.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2<4,>=2.7.3->tfx[kfp]<2) (2.1.3)\n",
      "Requirement already satisfied: kt-legacy in /opt/conda/lib/python3.9/site-packages (from keras-tuner<2,>=1.0.4->tfx[kfp]<2) (1.0.5)\n",
      "Collecting requests-toolbelt<1,>=0.8.0 (from kfp<2,>=1.8.14->tfx[kfp]<2)\n",
      "  Downloading requests_toolbelt-0.10.1-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kfp-server-api<2.0.0,>=1.1.2 (from kfp<2,>=1.8.14->tfx[kfp]<2)\n",
      "  Downloading kfp-server-api-1.8.5.tar.gz (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: jsonschema<5,>=3.0.1 in /opt/conda/lib/python3.9/site-packages (from kfp<2,>=1.8.14->tfx[kfp]<2) (4.17.3)\n",
      "Requirement already satisfied: tabulate<1,>=0.8.6 in /opt/conda/lib/python3.9/site-packages (from kfp<2,>=1.8.14->tfx[kfp]<2) (0.9.0)\n",
      "Collecting Deprecated<2,>=1.2.7 (from kfp<2,>=1.8.14->tfx[kfp]<2)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting strip-hints<1,>=0.1.8 (from kfp<2,>=1.8.14->tfx[kfp]<2)\n",
      "  Downloading strip-hints-0.1.10.tar.gz (29 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting docstring-parser<1,>=0.7.3 (from kfp<2,>=1.8.14->tfx[kfp]<2)\n",
      "  Downloading docstring_parser-0.15-py3-none-any.whl (36 kB)\n",
      "Collecting fire<1,>=0.3.1 (from kfp<2,>=1.8.14->tfx[kfp]<2)\n",
      "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: urllib3<2 in /opt/conda/lib/python3.9/site-packages (from kfp<2,>=1.8.14->tfx[kfp]<2) (1.26.15)\n",
      "Requirement already satisfied: pydantic<2,>=1.8.2 in /opt/conda/lib/python3.9/site-packages (from kfp<2,>=1.8.14->tfx[kfp]<2) (1.9.2)\n",
      "Collecting typer<1.0,>=0.3.2 (from kfp<2,>=1.8.14->tfx[kfp]<2)\n",
      "  Downloading typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi>=14.05.14 in /opt/conda/lib/python3.9/site-packages (from kubernetes<13,>=10.0.1->tfx[kfp]<2) (2023.5.7)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.9/site-packages (from kubernetes<13,>=10.0.1->tfx[kfp]<2) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging<21,>=20->tfx[kfp]<2) (3.0.9)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.9/site-packages (from portpicker<2,>=1.3.1->tfx[kfp]<2) (5.9.3)\n",
      "Collecting absl-py<2.0.0,>=0.9 (from tfx[kfp]<2)\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow<2.13,>=2.12.0->tfx[kfp]<2) (1.6.3)\n",
      "Collecting flatbuffers>=2.0 (from tensorflow<2.13,>=2.12.0->tfx[kfp]<2)\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.9/site-packages (from tensorflow<2.13,>=2.12.0->tfx[kfp]<2) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.9/site-packages (from tensorflow<2.13,>=2.12.0->tfx[kfp]<2) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow<2.13,>=2.12.0->tfx[kfp]<2) (3.1.0)\n",
      "Collecting jax>=0.3.15 (from tensorflow<2.13,>=2.12.0->tfx[kfp]<2)\n",
      "  Downloading jax-0.4.13.tar.gz (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting keras<2.13,>=2.12.0 (from tensorflow<2.13,>=2.12.0->tfx[kfp]<2)\n",
      "  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting libclang>=13.0.0 (from tensorflow<2.13,>=2.12.0->tfx[kfp]<2)\n",
      "  Downloading libclang-16.0.0-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.9/22.9 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy<2,>=1.16 (from tfx[kfp]<2)\n",
      "  Downloading numpy-1.24.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.9/site-packages (from tensorflow<2.13,>=2.12.0->tfx[kfp]<2) (3.3.0)\n",
      "Collecting tensorboard<2.13,>=2.12 (from tensorflow<2.13,>=2.12.0->tfx[kfp]<2)\n",
      "  Downloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m105.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow<2.13,>=2.12.0->tfx[kfp]<2)\n",
      "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow<2.13,>=2.12.0->tfx[kfp]<2) (1.1.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow<2.13,>=2.12.0->tfx[kfp]<2) (1.12.1)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow<2.13,>=2.12.0->tfx[kfp]<2)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.32.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow-data-validation<1.14.0,>=1.13.0->tfx[kfp]<2) (1.2.0)\n",
      "Collecting numpy<2,>=1.16 (from tfx[kfp]<2)\n",
      "  Downloading numpy-1.22.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas<2,>=1.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow-data-validation<1.14.0,>=1.13.0->tfx[kfp]<2) (1.4.4)\n",
      "Collecting pyfarmhash<0.4,>=0.2.2 (from tensorflow-data-validation<1.14.0,>=1.13.0->tfx[kfp]<2)\n",
      "  Downloading pyfarmhash-0.3.2.tar.gz (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.9/99.9 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tensorflow-metadata<1.14,>=1.13.1 (from tensorflow-data-validation<1.14.0,>=1.13.0->tfx[kfp]<2)\n",
      "  Downloading tensorflow_metadata-1.13.1-py3-none-any.whl (28 kB)\n",
      "Collecting ipython<8,>=7 (from tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2)\n",
      "  Downloading ipython-7.34.0-py3-none-any.whl (793 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m793.8/793.8 kB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ipywidgets<8,>=7 (from tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2)\n",
      "  Downloading ipywidgets-7.7.5-py2.py3-none-any.whl (123 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.9/123.9 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy<2,>=1.4.1 in /opt/conda/lib/python3.9/site-packages (from tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (1.10.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow<2.13,>=2.12.0->tfx[kfp]<2) (0.40.0)\n",
      "INFO: pip is looking at multiple versions of google-api-core[grpc] to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0 (from google-cloud-aiplatform<1.18,>=1.6.2->tfx[kfp]<2)\n",
      "  Downloading google_api_core-2.11.1-py3-none-any.whl (120 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.5/120.5 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_api_core-2.11.0-py3-none-any.whl (120 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.3/120.3 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_api_core-2.10.2-py3-none-any.whl (115 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.6/115.6 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_api_core-2.10.1-py3-none-any.whl (115 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.5/115.5 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_api_core-2.10.0-py3-none-any.whl (115 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_api_core-2.9.0-py3-none-any.whl (115 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.1/115.1 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_api_core-2.8.2-py3-none-any.whl (114 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of google-api-core[grpc] to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading google_api_core-2.8.1-py3-none-any.whl (114 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.7/114.7 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_api_core-2.8.0-py3-none-any.whl (114 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.7/114.7 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_api_core-1.33.2-py3-none-any.whl (115 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.5/115.5 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_api_core-1.33.1-py3-none-any.whl (115 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.5/115.5 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_api_core-1.33.0-py3-none-any.whl (115 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.2/115.2 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.40->tfx[kfp]<2) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.40->tfx[kfp]<2) (4.9)\n",
      "Requirement already satisfied: grpc-google-iam-v1<0.13dev,>=0.12.3 in /opt/conda/lib/python3.9/site-packages (from google-cloud-bigtable<2,>=0.31.1->apache-beam[gcp]<3,>=2.40->tfx[kfp]<2) (0.12.6)\n",
      "INFO: pip is looking at multiple versions of google-cloud-dlp to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting google-cloud-dlp<4,>=3.0.0 (from apache-beam[gcp]<3,>=2.40->tfx[kfp]<2)\n",
      "  Downloading google_cloud_dlp-3.12.2-py2.py3-none-any.whl (143 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/143.4 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_cloud_dlp-3.12.0-py2.py3-none-any.whl (143 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/143.4 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_cloud_dlp-3.11.1-py2.py3-none-any.whl (131 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.4/131.4 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_cloud_dlp-3.11.0-py2.py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_cloud_dlp-3.10.1-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_cloud_dlp-3.10.0-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_cloud_dlp-3.9.2-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.3/125.3 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting grpcio<2,>=1.28.1 (from tfx[kfp]<2)\n",
      "  Downloading grpcio-1.56.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m106.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of google-cloud-pubsub to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting google-cloud-pubsub<3,>=2.1.0 (from apache-beam[gcp]<3,>=2.40->tfx[kfp]<2)\n",
      "  Downloading google_cloud_pubsub-2.17.0-py2.py3-none-any.whl (265 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.1/265.1 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_cloud_pubsub-2.16.1-py2.py3-none-any.whl (263 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.0/264.0 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_cloud_pubsub-2.16.0-py2.py3-none-any.whl (263 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.9/263.9 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_cloud_pubsub-2.15.2-py2.py3-none-any.whl (243 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.1/243.1 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_cloud_pubsub-2.15.1-py2.py3-none-any.whl (243 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.0/243.0 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_cloud_pubsub-2.15.0-py2.py3-none-any.whl (242 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.0/243.0 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_cloud_pubsub-2.14.1-py2.py3-none-any.whl (242 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.2/242.2 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of google-cloud-pubsub to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading google_cloud_pubsub-2.14.0-py2.py3-none-any.whl (241 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.5/241.5 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_cloud_pubsub-2.13.12-py2.py3-none-any.whl (238 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.3/238.3 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_cloud_pubsub-2.13.11-py2.py3-none-any.whl (236 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.0/237.0 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: grpcio-status>=1.16.0 in /opt/conda/lib/python3.9/site-packages (from google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.40->tfx[kfp]<2) (1.46.3)\n",
      "Requirement already satisfied: overrides<7.0.0,>=6.0.1 in /opt/conda/lib/python3.9/site-packages (from google-cloud-pubsublite<2,>=1.2.0->apache-beam[gcp]<3,>=2.40->tfx[kfp]<2) (6.5.0)\n",
      "INFO: pip is looking at multiple versions of google-cloud-pubsublite to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting google-cloud-pubsublite<2,>=1.2.0 (from apache-beam[gcp]<3,>=2.40->tfx[kfp]<2)\n",
      "  Downloading google_cloud_pubsublite-1.8.3-py2.py3-none-any.whl (288 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.1/288.1 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_cloud_pubsublite-1.8.1-py2.py3-none-any.whl (288 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.1/288.1 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_cloud_pubsublite-1.8.0-py2.py3-none-any.whl (287 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_cloud_pubsublite-1.7.0-py2.py3-none-any.whl (273 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.9/273.9 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_cloud_pubsublite-1.6.0-py2.py3-none-any.whl (271 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.1/271.1 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of google-cloud-resource-manager to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting google-cloud-resource-manager<3.0.0dev,>=1.3.3 (from google-cloud-aiplatform<1.18,>=1.6.2->tfx[kfp]<2)\n",
      "  Downloading google_cloud_resource_manager-1.10.2-py2.py3-none-any.whl (321 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.3/321.3 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_cloud_resource_manager-1.10.0-py2.py3-none-any.whl (321 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.4/321.4 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_cloud_resource_manager-1.9.1-py2.py3-none-any.whl (276 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.8/276.8 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_cloud_resource_manager-1.9.0-py2.py3-none-any.whl (276 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.8/276.8 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_cloud_resource_manager-1.8.1-py2.py3-none-any.whl (235 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.7/235.7 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_cloud_resource_manager-1.8.0-py2.py3-none-any.whl (235 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.3/235.3 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_cloud_resource_manager-1.7.0-py2.py3-none-any.whl (235 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.3/235.3 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of google-cloud-resource-manager to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading google_cloud_resource_manager-1.6.3-py2.py3-none-any.whl (233 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.8/233.8 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of google-cloud-spanner to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting google-cloud-spanner<4,>=3.0.0 (from apache-beam[gcp]<3,>=2.40->tfx[kfp]<2)\n",
      "  Downloading google_cloud_spanner-3.35.1-py2.py3-none-any.whl (332 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m332.6/332.6 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_cloud_spanner-3.35.0-py2.py3-none-any.whl (331 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.8/331.8 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_cloud_spanner-3.34.0-py2.py3-none-any.whl (331 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.3/331.3 kB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_cloud_spanner-3.33.0-py2.py3-none-any.whl (328 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.5/328.5 kB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_cloud_spanner-3.32.0-py2.py3-none-any.whl (327 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.7/327.7 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_cloud_spanner-3.31.0-py2.py3-none-any.whl (327 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.6/327.6 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_cloud_spanner-3.30.0-py2.py3-none-any.whl (327 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.3/327.3 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of google-cloud-spanner to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading google_cloud_spanner-3.29.0-py2.py3-none-any.whl (327 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.3/327.3 kB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_cloud_spanner-3.28.0-py2.py3-none-any.whl (327 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.1/327.1 kB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_cloud_spanner-3.27.1-py2.py3-none-any.whl (300 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.0/300.0 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_cloud_spanner-3.27.0-py2.py3-none-any.whl (297 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.1/297.1 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_cloud_spanner-3.26.0-py2.py3-none-any.whl (294 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.4/294.4 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sqlparse>=0.3.0 in /opt/conda/lib/python3.9/site-packages (from google-cloud-spanner<4,>=3.0.0->apache-beam[gcp]<3,>=2.40->tfx[kfp]<2) (0.4.4)\n",
      "INFO: pip is looking at multiple versions of google-cloud-vision to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting google-cloud-vision<4,>=2 (from apache-beam[gcp]<3,>=2.40->tfx[kfp]<2)\n",
      "  Downloading google_cloud_vision-3.4.4-py2.py3-none-any.whl (444 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.0/444.0 kB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_cloud_vision-3.4.3-py2.py3-none-any.whl (444 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.0/444.0 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_cloud_vision-3.4.1-py2.py3-none-any.whl (444 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.3/444.3 kB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_cloud_vision-3.4.0-py2.py3-none-any.whl (444 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.2/444.2 kB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_cloud_vision-3.3.1-py2.py3-none-any.whl (393 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.5/393.5 kB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_cloud_vision-3.3.0-py2.py3-none-any.whl (386 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.5/386.5 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading google_cloud_vision-3.2.0-py2.py3-none-any.whl (386 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.5/386.5 kB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of google-cloud-vision to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading google_cloud_vision-3.1.4-py2.py3-none-any.whl (390 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.4/390.4 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.9/site-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3,>=2.26.0->tfx[kfp]<2) (1.5.0)\n",
      "Requirement already satisfied: docopt in /opt/conda/lib/python3.9/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.40->tfx[kfp]<2) (0.6.2)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.9/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (0.18.2)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.9/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.9/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (0.7.5)\n",
      "Requirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.9/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (5.9.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (3.0.38)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.9/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (2.15.1)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.9/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.9/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (0.1.6)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.9/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (4.8.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.9/site-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (6.23.1)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.9/site-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (0.2.0)\n",
      "Collecting widgetsnbextension~=3.6.4 (from ipywidgets<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2)\n",
      "  Downloading widgetsnbextension-3.6.4-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jupyterlab-widgets<3,>=1.0.0 (from ipywidgets<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2)\n",
      "  Downloading jupyterlab_widgets-1.1.4-py3-none-any.whl (246 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.1/246.1 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ml-dtypes>=0.1.0 (from jax>=0.3.15->tensorflow<2.13,>=2.12.0->tfx[kfp]<2)\n",
      "  Downloading ml_dtypes-0.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata>=4.6 in /opt/conda/lib/python3.9/site-packages (from jax>=0.3.15->tensorflow<2.13,>=2.12.0->tfx[kfp]<2) (6.6.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema<5,>=3.0.1->kfp<2,>=1.8.14->tfx[kfp]<2) (0.19.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /opt/conda/lib/python3.9/site-packages (from oauth2client>=1.4.12->google-apitools<1,>=0.5->tfx[kfp]<2) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.40->tfx[kfp]<2) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.40->tfx[kfp]<2) (3.4)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tfx[kfp]<2)\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tfx[kfp]<2) (3.4.3)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tfx[kfp]<2)\n",
      "  Downloading tensorboard_data_server-0.7.1-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m102.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tfx[kfp]<2) (2.3.6)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from requests-oauthlib->kubernetes<13,>=10.0.1->tfx[kfp]<2) (3.2.2)\n",
      "INFO: pip is looking at multiple versions of google-auth-oauthlib to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tfx[kfp]<2)\n",
      "  Downloading google_auth_oauthlib-0.8.0-py2.py3-none-any.whl (19 kB)\n",
      "  Downloading google_auth_oauthlib-0.7.1-py2.py3-none-any.whl (19 kB)\n",
      "  Downloading google_auth_oauthlib-0.7.0-py2.py3-none-any.whl (19 kB)\n",
      "  Downloading google_auth_oauthlib-0.5.3-py2.py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata>=4.6->jax>=0.3.15->tensorflow<2.13,>=2.12.0->tfx[kfp]<2) (3.15.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/conda/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (0.1.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (1.6.7)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (7.4.9)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (5.3.1)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (1.5.6)\n",
      "Requirement already satisfied: pyzmq>=20 in /opt/conda/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (25.1.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (6.3.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.9/site-packages (from jedi>=0.16->ipython<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.9/site-packages (from pexpect>4.3->ipython<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (0.2.6)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.9/site-packages (from widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (6.5.4)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.9/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (0.4)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.9/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (3.5.3)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (21.3.0)\n",
      "Requirement already satisfied: nbformat in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (5.9.0)\n",
      "Requirement already satisfied: nbconvert>=5 in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (7.5.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (0.17.1)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (0.17.0)\n",
      "Requirement already satisfied: nbclassic>=0.4.7 in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (1.0.0)\n",
      "Requirement already satisfied: jupyter-server>=1.8 in /opt/conda/lib/python3.9/site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (1.24.0)\n",
      "Requirement already satisfied: notebook-shim>=0.2.3 in /opt/conda/lib/python3.9/site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (0.2.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (4.12.2)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /opt/conda/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (6.0.0)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (0.2.2)\n",
      "Requirement already satisfied: mistune<3,>=2.0.3 in /opt/conda/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (2.0.5)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /opt/conda/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (0.8.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in /opt/conda/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (1.2.1)\n",
      "Requirement already satisfied: fastjsonschema in /opt/conda/lib/python3.9/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (2.17.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.9/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (21.2.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.9/site-packages (from bleach!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (0.5.1)\n",
      "Requirement already satisfied: anyio<4,>=3.1.0 in /opt/conda/lib/python3.9/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (3.7.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (1.15.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.9/site-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (2.3.2.post1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.9/site-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.9/site-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (1.1.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.9/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8,>=7->tensorflow-model-analysis<0.45.0,>=0.44.0->tfx[kfp]<2) (2.21)\n",
      "Building wheels for collected packages: kfp, fire, jax, kfp-server-api, pyfarmhash, strip-hints\n",
      "  Building wheel for kfp (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kfp: filename=kfp-1.8.22-py3-none-any.whl size=426971 sha256=7bb6d6f64cae6cf18d8198de3b65faf868861b13a993ec6c1cd30809d6013f9d\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/7c/3d/15/d071fc386c3286d790dcd75fc86ce32058839764a81c19c908\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116932 sha256=3476f4e200d44c68284d218f2cdc415c51efa938302f11159ab4dcca5f1762ba\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/f7/f1/89/b9ea2bf8f80ec027a88fef1d354b3816b4d3d29530988972f6\n",
      "  Building wheel for jax (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jax: filename=jax-0.4.13-py3-none-any.whl size=1518707 sha256=ea725170c0574b5caca3fcb9f5538358e3b7525682be6cc199f2ba5a81849223\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/ac/c9/8c/f4c803770fde18dcdd82e84675eb6add1c0d1035f7214a96fa\n",
      "  Building wheel for kfp-server-api (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kfp-server-api: filename=kfp_server_api-1.8.5-py3-none-any.whl size=99699 sha256=357ec59bede18db90250122ed3058566e2735f9350dcf5afa0d7888a75fe1f94\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/eb/ee/9b/1bb6039c237dcc9586d2b2034107b003d86afc7cbdc7613b5d\n",
      "  Building wheel for pyfarmhash (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyfarmhash: filename=pyfarmhash-0.3.2-cp39-cp39-linux_x86_64.whl size=13872 sha256=bc9b3e3d91a01904f0a3201b5a91b685867bf1d3cb1cd35d1ca6d4c449a1e407\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/de/2b/b1/c541160670d70f4b08c4786f4e155337d4baeaa3e01d9d1400\n",
      "  Building wheel for strip-hints (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for strip-hints: filename=strip_hints-0.1.10-py2.py3-none-any.whl size=22284 sha256=80d4342a3a8ac89605303808e7f2c3bf2cf828c6cc31c0930b2b91c9d488542c\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/eb/82/45/f4240f75b8cd041477e71032ea28652c913c0323f479032018\n",
      "Successfully built kfp fire jax kfp-server-api pyfarmhash strip-hints\n",
      "Installing collected packages: pyfarmhash, libclang, flatbuffers, typer, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, strip-hints, pyyaml, protobuf, portpicker, packaging, numpy, keras, jupyterlab-widgets, grpcio, fire, docstring-parser, Deprecated, attrs, absl-py, tensorflow-hub, requests-toolbelt, pyarrow, ml-metadata, ml-dtypes, kfp-server-api, kfp-pipeline-spec, ipython, docker, tensorflow-metadata, kubernetes, jax, google-auth-oauthlib, google-api-core, tensorboard, tensorflow, ml-pipelines-sdk, google-cloud-vision, google-cloud-spanner, google-cloud-resource-manager, google-cloud-pubsub, google-cloud-dlp, google-cloud-bigquery, tensorflow-serving-api, kfp, google-cloud-pubsublite, google-cloud-aiplatform, tfx-bsl, tensorflow-transform, tensorflow-data-validation, widgetsnbextension, ipywidgets, tensorflow-model-analysis, tfx\n",
      "  Attempting uninstall: flatbuffers\n",
      "    Found existing installation: flatbuffers 1.12\n",
      "    Uninstalling flatbuffers-1.12:\n",
      "      Successfully uninstalled flatbuffers-1.12\n",
      "  Attempting uninstall: tensorflow-io-gcs-filesystem\n",
      "    Found existing installation: tensorflow-io-gcs-filesystem 0.21.0\n",
      "    Uninstalling tensorflow-io-gcs-filesystem-0.21.0:\n",
      "      Successfully uninstalled tensorflow-io-gcs-filesystem-0.21.0\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.6.0\n",
      "    Uninstalling tensorflow-estimator-2.6.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.6.0\n",
      "  Attempting uninstall: tensorboard-data-server\n",
      "    Found existing installation: tensorboard-data-server 0.6.1\n",
      "    Uninstalling tensorboard-data-server-0.6.1:\n",
      "      Successfully uninstalled tensorboard-data-server-0.6.1\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 6.0\n",
      "    Uninstalling PyYAML-6.0:\n",
      "      Successfully uninstalled PyYAML-6.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.1\n",
      "    Uninstalling packaging-23.1:\n",
      "      Successfully uninstalled packaging-23.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.6.0\n",
      "    Uninstalling keras-2.6.0:\n",
      "      Successfully uninstalled keras-2.6.0\n",
      "  Attempting uninstall: jupyterlab-widgets\n",
      "    Found existing installation: jupyterlab-widgets 3.0.7\n",
      "    Uninstalling jupyterlab-widgets-3.0.7:\n",
      "      Successfully uninstalled jupyterlab-widgets-3.0.7\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.46.4\n",
      "    Uninstalling grpcio-1.46.4:\n",
      "      Successfully uninstalled grpcio-1.46.4\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 23.1.0\n",
      "    Uninstalling attrs-23.1.0:\n",
      "      Successfully uninstalled attrs-23.1.0\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 0.15.0\n",
      "    Uninstalling absl-py-0.15.0:\n",
      "      Successfully uninstalled absl-py-0.15.0\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 13] Permission denied: '_flagvalues.cpython-39.pyc'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Use the latest version of pip.\n",
    "!pip install --upgrade pip\n",
    "!pip install --upgrade \"tfx[kfp]<2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cb3e4bd6-be70-460e-930d-67ad839bac36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-12 12:55:59.538726: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.12.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:TensorFlow Decision Forests 1.4.0 is compatible with the following TensorFlow Versions: ['2.12.0']. However, TensorFlow 2.12.1 was detected. This can cause issues with the TF API and symbols in the custom C++ ops. See the TF and TF-DF compatibility table at https://github.com/tensorflow/decision-forests/blob/main/documentation/known_issues.md#compatibility-table.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFX version: 1.13.0\n",
      "KFP version: 1.8.22\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print('TensorFlow version: {}'.format(tf.__version__))\n",
    "from tfx import v1 as tfx\n",
    "print('TFX version: {}'.format(tfx.__version__))\n",
    "import kfp\n",
    "print('KFP version: {}'.format(kfp.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6c3e82f8-68e2-494d-b83f-e62b4f01f44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx import v1 as tfx\n",
    "import tensorflow_data_validation as tfdv\n",
    "import sys\n",
    "from tfx.components import ImportExampleGen\n",
    "from tfx.components import CsvExampleGen\n",
    "from tfx.components import StatisticsGen\n",
    "from tfx.components import SchemaGen\n",
    "from tfx.components import Transform\n",
    "from tfx.v1 import proto\n",
    "from tfx.proto import example_gen_pb2\n",
    "from tfx.components import Trainer\n",
    "from tfx.components import ExampleValidator\n",
    "from tfx.components import InfraValidator\n",
    "from tfx.components import Pusher\n",
    "from tfx.components import Tuner\n",
    "from tfx.components import Evaluator\n",
    "import keras_tuner\n",
    "from tfx.dsl.experimental import latest_blessed_model_resolver\n",
    "from tfx.dsl.components.common import resolver\n",
    "from tfx.dsl.experimental import latest_blessed_model_resolver\n",
    "from tfx.types import Channel\n",
    "from tfx.types.standard_artifacts import Model\n",
    "from tfx.types.standard_artifacts import ModelBlessing\n",
    "import tensorflow_model_analysis as tfma\n",
    "import apache_beam as beam\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e18088fc-384c-48de-8b64-4b5f20fa8651",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_CLOUD_PROJECT = 'itp-ml-sndbx'     \n",
    "GOOGLE_CLOUD_REGION = 'us-west1'      \n",
    "GCS_BUCKET_NAME = 'gcp-ml-pipeline'          \n",
    "\n",
    "if not (GOOGLE_CLOUD_PROJECT and GOOGLE_CLOUD_REGION and GCS_BUCKET_NAME):\n",
    "    from absl import logging\n",
    "    logging.error('Please set all required parameters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b41232dc-10e3-4b50-96b3-e1fbc1f06e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "!gcloud config set project {GOOGLE_CLOUD_PROJECT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5e9b401b-30bb-4118-b47e-011861de2fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_NAME = 'taxicab-pipeline'\n",
    "PIPELINE_ROOT = 'gs://gcp-ml-pipeline/pipeline/taxicab-pipeline'\n",
    "DATA_ROOT = 'gs://gcp-ml-pipeline/pipeline/taxicab-pipeline/data'\n",
    "SERVING_MODEL_DIR = 'gs://gcp-ml-pipeline/pipeline/taxicab-pipeline/serving_model'\n",
    "METADATA_ROOT = 'gs://gcp-ml-pipeline/pipeline/taxicab-pipeline/metadata'\n",
    "LABEL_NAME = 'fare_amount'\n",
    "ENDPOINT_NAME = 'prediction-' + PIPELINE_NAME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "19789fab-ec07-40cb-964b-a9fbe7a91292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_pipeline(pipeline_name: str, pipeline_root: str, data_root: str, endpoint_name: str, serving_model_dir: str, metadata_root: str, region: str\n",
    "                     ) -> tfx.dsl.Pipeline:\n",
    "    \n",
    "    output = proto.Output(\n",
    "             split_config=example_gen_pb2.SplitConfig(splits=[\n",
    "                 proto.SplitConfig.Split(name='train', hash_buckets=3),\n",
    "                 proto.SplitConfig.Split(name='eval', hash_buckets=1)\n",
    "             ]))\n",
    "\n",
    "    example_gen = CsvExampleGen(input_base='gs://gcp-ml-pipeline/pipeline/taxicab-pipeline/data', output_config=output)\n",
    "    print(example_gen)\n",
    "    \n",
    "    stats_options = tfdv.StatsOptions(label_feature=LABEL_NAME)\n",
    "    statistics_gen = StatisticsGen(examples=example_gen.outputs['examples'], stats_options=stats_options)\n",
    "    \n",
    "    schema_gen = SchemaGen(\n",
    "        statistics=statistics_gen.outputs['statistics'], infer_feature_shape=True)\n",
    "    \n",
    "    transform = Transform(examples = example_gen.outputs['examples'], schema = schema_gen.outputs['schema'], module_file='./preprocessing_fn.py', materialize=True)  \n",
    "    \n",
    "    tuner = Tuner(\n",
    "    module_file='./tuner.py',\n",
    "    examples=transform.outputs['transformed_examples'],\n",
    "    transform_graph = transform.outputs['transform_graph'],\n",
    "    schema=transform.outputs['post_transform_schema'],\n",
    "    train_args=proto.TrainArgs(splits=['train'], num_steps=2500),\n",
    "    eval_args=proto.EvalArgs(splits=['eval'], num_steps=50),\n",
    "    # tune_args=tune_args\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "    module_file='./model.py',\n",
    "    examples=transform.outputs['transformed_examples'],\n",
    "    transform_graph = transform.outputs['transform_graph'],\n",
    "    schema=transform.outputs['post_transform_schema'],\n",
    "    hyperparameters = tuner.outputs['best_hyperparameters'],\n",
    "    train_args=proto.TrainArgs(splits=['train'], num_steps=7500),\n",
    "    eval_args=proto.EvalArgs(splits=['eval'], num_steps=2500))\n",
    "\n",
    "    \n",
    "    example_validator = ExampleValidator(statistics=statistics_gen.outputs['statistics'], schema=schema_gen.outputs['schema'])\n",
    "    \n",
    "    '''infra_validator = tfx.components.InfraValidator(\n",
    "      model=trainer.outputs['model'],\n",
    "      examples=example_gen.outputs['examples'],\n",
    "      serving_spec=tfx.proto.ServingSpec(\n",
    "          # TODO(b/244254788): Roll back to the 'latest' tag.\n",
    "          tensorflow_serving=tfx.proto.TensorFlowServing(tags=['latest']),\n",
    "          local_docker=tfx.proto.LocalDockerConfig()\n",
    "      ),\n",
    "      request_spec=tfx.proto.RequestSpec(\n",
    "          tensorflow_serving=tfx.proto.TensorFlowServingRequestSpec(),\n",
    "          # If this flag is set, InfraValidator will produce a model with\n",
    "          # warmup requests (in its outputs['blessing']).\n",
    "          make_warmup=True),\n",
    "      validation_spec=tfx.proto.ValidationSpec(\n",
    "        # How much time to wait for model to load before automatically making\n",
    "        # validation fail.\n",
    "        max_loading_time_seconds=60,\n",
    "        # How many times to retry if infra validation fails.\n",
    "        num_tries=3\n",
    "        )\n",
    "    )'''\n",
    "    \n",
    "    model_resolver = tfx.dsl.Resolver(\n",
    "      strategy_class=tfx.dsl.experimental.LatestBlessedModelStrategy,\n",
    "      model=tfx.dsl.Channel(type=tfx.types.standard_artifacts.Model),\n",
    "      model_blessing=tfx.dsl.Channel(\n",
    "          type=tfx.types.standard_artifacts.ModelBlessing))\n",
    "\n",
    "    eval_config = tfma.EvalConfig(\n",
    "          model_specs=[\n",
    "              tfma.ModelSpec(signature_name='serving_default', label_key=LABEL_NAME, preprocessing_function_names=['transform_features'])] ,\n",
    "          slicing_specs=[\n",
    "              tfma.SlicingSpec(),\n",
    "              # tfma.SlicingSpec(feature_keys=['trip_start_hour'])\n",
    "          ],\n",
    "          metrics_specs=[\n",
    "              tfma.MetricsSpec(\n",
    "                  thresholds={\n",
    "                      'mse':\n",
    "                          tfma.MetricThreshold(\n",
    "                              value_threshold=tfma.GenericValueThreshold(\n",
    "                                  upper_bound={'value': 2e2}),\n",
    "                              change_threshold=tfma.GenericChangeThreshold(\n",
    "                                  direction=tfma.MetricDirection.LOWER_IS_BETTER,\n",
    "                                  absolute={'value': 1e-1}))\n",
    "                  }\n",
    "          )]\n",
    "    )\n",
    "\n",
    "\n",
    "    evaluator = tfx.components.Evaluator(\n",
    "        examples=example_gen.outputs['examples'],\n",
    "        model=trainer.outputs['model'],\n",
    "        baseline_model=model_resolver.outputs['model'],\n",
    "        eval_config=eval_config\n",
    "    )\n",
    "\n",
    "    serving_image = 'us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-9:latest'\n",
    "    vertex_serving_spec = {\n",
    "      'project_id': GOOGLE_CLOUD_PROJECT,\n",
    "      'endpoint_name': endpoint_name,\n",
    "  }\n",
    "        \n",
    "    pusher = tfx.extensions.google_cloud_ai_platform.Pusher(\n",
    "        model=trainer.outputs['model'],\n",
    "         custom_config={\n",
    "          tfx.extensions.google_cloud_ai_platform.ENABLE_VERTEX_KEY:\n",
    "              True,\n",
    "          tfx.extensions.google_cloud_ai_platform.VERTEX_REGION_KEY:\n",
    "              region,\n",
    "          tfx.extensions.google_cloud_ai_platform.VERTEX_CONTAINER_IMAGE_URI_KEY:\n",
    "              serving_image,\n",
    "          tfx.extensions.google_cloud_ai_platform.SERVING_ARGS_KEY:\n",
    "            vertex_serving_spec,\n",
    "      }\n",
    "    )\n",
    "\n",
    "    components = [\n",
    "              example_gen,\n",
    "              statistics_gen,\n",
    "              schema_gen,\n",
    "              transform,\n",
    "              trainer,\n",
    "              example_validator,\n",
    "              tuner,\n",
    "              evaluator,\n",
    "              pusher,\n",
    "              model_resolver,\n",
    "        ]\n",
    "        # }}}\n",
    "        # {{{ Pipeline Definition\n",
    "    pipeline_name=pipeline_name\n",
    "    pipeline_root=pipeline_root\n",
    "    metadata_path='gs://gcp-ml-pipeline/taxicab-pipeline/metadata/metadata.db'\n",
    "        \n",
    "    pipeline_options = PipelineOptions([\n",
    "    \"--runner=PortableRunner\",\n",
    "    \"--job_endpoint=localhost:8099\",\n",
    "    \"--environment_type=LOOPBACK\"\n",
    "        ])\n",
    "\n",
    "    beam_pipeline_args = [\n",
    "            \"--runner=PortableRunner\",\n",
    "            \"--job_endpoint=localhost:8099\",\n",
    "            \"--environment_type=LOOPBACK\",\n",
    "            \"--spark_version=3\",\n",
    "            \"--machine_type=n1-standard-8\"\n",
    "        ]\n",
    "\n",
    "    pipeline = tfx.dsl.Pipeline(\n",
    "              pipeline_name=pipeline_name,\n",
    "              pipeline_root=pipeline_root,\n",
    "              metadata_connection_config=tfx.orchestration.metadata.sqlite_metadata_connection_config(metadata_path),\n",
    "              components=components,\n",
    "        enable_cache=True)\n",
    "        \n",
    "    return pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0c133c18-b2a6-4168-9633-06dcc5005429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CsvExampleGen(spec: <tfx.types.standard_component_specs.FileBasedExampleGenSpec object at 0x7f74dae2d9d0>, executor_spec: <tfx.dsl.components.base.executor_spec.BeamExecutorSpec object at 0x7f74dae2d670>, driver_class: <class 'tfx.components.example_gen.driver.FileBasedDriver'>, component_id: CsvExampleGen, inputs: {}, outputs: {'examples': OutputChannel(artifact_type=Examples, producer_component_id=CsvExampleGen, output_key=examples, additional_properties={}, additional_custom_properties={}, _input_trigger=None})\n",
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "copying model.py -> build/lib\n",
      "copying tfx-client.py -> build/lib\n",
      "copying tuner.py -> build/lib\n",
      "copying transparency.py -> build/lib\n",
      "copying preprocessing_fn.py -> build/lib\n",
      "installing to /var/tmp/tmpxtdtzc34\n",
      "running install\n",
      "running install_lib\n",
      "copying build/lib/model.py -> /var/tmp/tmpxtdtzc34\n",
      "copying build/lib/tuner.py -> /var/tmp/tmpxtdtzc34\n",
      "copying build/lib/preprocessing_fn.py -> /var/tmp/tmpxtdtzc34\n",
      "copying build/lib/tfx-client.py -> /var/tmp/tmpxtdtzc34\n",
      "copying build/lib/transparency.py -> /var/tmp/tmpxtdtzc34\n",
      "running install_egg_info\n",
      "running egg_info\n",
      "creating tfx_user_code_Transform.egg-info\n",
      "writing tfx_user_code_Transform.egg-info/PKG-INFO\n",
      "writing dependency_links to tfx_user_code_Transform.egg-info/dependency_links.txt\n",
      "writing top-level names to tfx_user_code_Transform.egg-info/top_level.txt\n",
      "writing manifest file 'tfx_user_code_Transform.egg-info/SOURCES.txt'\n",
      "reading manifest file 'tfx_user_code_Transform.egg-info/SOURCES.txt'\n",
      "writing manifest file 'tfx_user_code_Transform.egg-info/SOURCES.txt'\n",
      "Copying tfx_user_code_Transform.egg-info to /var/tmp/tmpxtdtzc34/tfx_user_code_Transform-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7-py3.9.egg-info\n",
      "running install_scripts\n",
      "creating /var/tmp/tmpxtdtzc34/tfx_user_code_Transform-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7.dist-info/WHEEL\n",
      "creating '/var/tmp/tmp1ied8x1g/tfx_user_code_Transform-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7-py3-none-any.whl' and adding '/var/tmp/tmpxtdtzc34' to it\n",
      "adding 'model.py'\n",
      "adding 'preprocessing_fn.py'\n",
      "adding 'tfx-client.py'\n",
      "adding 'transparency.py'\n",
      "adding 'tuner.py'\n",
      "adding 'tfx_user_code_Transform-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7.dist-info/METADATA'\n",
      "adding 'tfx_user_code_Transform-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7.dist-info/WHEEL'\n",
      "adding 'tfx_user_code_Transform-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7.dist-info/top_level.txt'\n",
      "adding 'tfx_user_code_Transform-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7.dist-info/RECORD'\n",
      "removing /var/tmp/tmpxtdtzc34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "!!\n",
      "\n",
      "        ********************************************************************************\n",
      "        Please avoid running ``setup.py`` directly.\n",
      "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
      "        other standards-based tools.\n",
      "\n",
      "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "        ********************************************************************************\n",
      "\n",
      "!!\n",
      "  self.initialize_options()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "copying model.py -> build/lib\n",
      "copying tfx-client.py -> build/lib\n",
      "copying tuner.py -> build/lib\n",
      "copying transparency.py -> build/lib\n",
      "copying preprocessing_fn.py -> build/lib\n",
      "installing to /var/tmp/tmpi3017w18\n",
      "running install\n",
      "running install_lib\n",
      "copying build/lib/model.py -> /var/tmp/tmpi3017w18\n",
      "copying build/lib/tuner.py -> /var/tmp/tmpi3017w18\n",
      "copying build/lib/preprocessing_fn.py -> /var/tmp/tmpi3017w18\n",
      "copying build/lib/tfx-client.py -> /var/tmp/tmpi3017w18\n",
      "copying build/lib/transparency.py -> /var/tmp/tmpi3017w18\n",
      "running install_egg_info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "!!\n",
      "\n",
      "        ********************************************************************************\n",
      "        Please avoid running ``setup.py`` directly.\n",
      "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
      "        other standards-based tools.\n",
      "\n",
      "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "        ********************************************************************************\n",
      "\n",
      "!!\n",
      "  self.initialize_options()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running egg_info\n",
      "creating tfx_user_code_Tuner.egg-info\n",
      "writing tfx_user_code_Tuner.egg-info/PKG-INFO\n",
      "writing dependency_links to tfx_user_code_Tuner.egg-info/dependency_links.txt\n",
      "writing top-level names to tfx_user_code_Tuner.egg-info/top_level.txt\n",
      "writing manifest file 'tfx_user_code_Tuner.egg-info/SOURCES.txt'\n",
      "reading manifest file 'tfx_user_code_Tuner.egg-info/SOURCES.txt'\n",
      "writing manifest file 'tfx_user_code_Tuner.egg-info/SOURCES.txt'\n",
      "Copying tfx_user_code_Tuner.egg-info to /var/tmp/tmpi3017w18/tfx_user_code_Tuner-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7-py3.9.egg-info\n",
      "running install_scripts\n",
      "creating /var/tmp/tmpi3017w18/tfx_user_code_Tuner-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7.dist-info/WHEEL\n",
      "creating '/var/tmp/tmpai1qc8tq/tfx_user_code_Tuner-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7-py3-none-any.whl' and adding '/var/tmp/tmpi3017w18' to it\n",
      "adding 'model.py'\n",
      "adding 'preprocessing_fn.py'\n",
      "adding 'tfx-client.py'\n",
      "adding 'transparency.py'\n",
      "adding 'tuner.py'\n",
      "adding 'tfx_user_code_Tuner-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7.dist-info/METADATA'\n",
      "adding 'tfx_user_code_Tuner-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7.dist-info/WHEEL'\n",
      "adding 'tfx_user_code_Tuner-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7.dist-info/top_level.txt'\n",
      "adding 'tfx_user_code_Tuner-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7.dist-info/RECORD'\n",
      "removing /var/tmp/tmpi3017w18\n",
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "copying model.py -> build/lib\n",
      "copying tfx-client.py -> build/lib\n",
      "copying tuner.py -> build/lib\n",
      "copying transparency.py -> build/lib\n",
      "copying preprocessing_fn.py -> build/lib\n",
      "installing to /var/tmp/tmpgs9zsncj\n",
      "running install\n",
      "running install_lib\n",
      "copying build/lib/model.py -> /var/tmp/tmpgs9zsncj\n",
      "copying build/lib/tuner.py -> /var/tmp/tmpgs9zsncj\n",
      "copying build/lib/preprocessing_fn.py -> /var/tmp/tmpgs9zsncj\n",
      "copying build/lib/tfx-client.py -> /var/tmp/tmpgs9zsncj\n",
      "copying build/lib/transparency.py -> /var/tmp/tmpgs9zsncj\n",
      "running install_egg_info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "!!\n",
      "\n",
      "        ********************************************************************************\n",
      "        Please avoid running ``setup.py`` directly.\n",
      "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
      "        other standards-based tools.\n",
      "\n",
      "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "        ********************************************************************************\n",
      "\n",
      "!!\n",
      "  self.initialize_options()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running egg_info\n",
      "creating tfx_user_code_Trainer.egg-info\n",
      "writing tfx_user_code_Trainer.egg-info/PKG-INFO\n",
      "writing dependency_links to tfx_user_code_Trainer.egg-info/dependency_links.txt\n",
      "writing top-level names to tfx_user_code_Trainer.egg-info/top_level.txt\n",
      "writing manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "reading manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "writing manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "Copying tfx_user_code_Trainer.egg-info to /var/tmp/tmpgs9zsncj/tfx_user_code_Trainer-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7-py3.9.egg-info\n",
      "running install_scripts\n",
      "creating /var/tmp/tmpgs9zsncj/tfx_user_code_Trainer-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7.dist-info/WHEEL\n",
      "creating '/var/tmp/tmptm4rq25p/tfx_user_code_Trainer-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7-py3-none-any.whl' and adding '/var/tmp/tmpgs9zsncj' to it\n",
      "adding 'model.py'\n",
      "adding 'preprocessing_fn.py'\n",
      "adding 'tfx-client.py'\n",
      "adding 'transparency.py'\n",
      "adding 'tuner.py'\n",
      "adding 'tfx_user_code_Trainer-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7.dist-info/METADATA'\n",
      "adding 'tfx_user_code_Trainer-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7.dist-info/WHEEL'\n",
      "adding 'tfx_user_code_Trainer-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7.dist-info/top_level.txt'\n",
      "adding 'tfx_user_code_Trainer-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7.dist-info/RECORD'\n",
      "removing /var/tmp/tmpgs9zsncj\n"
     ]
    }
   ],
   "source": [
    "PIPELINE_DEFINITION_FILE = PIPELINE_NAME + '_pipeline.json'\n",
    "\n",
    "runner = tfx.orchestration.experimental.KubeflowV2DagRunner(\n",
    "    config=tfx.orchestration.experimental.KubeflowV2DagRunnerConfig(),\n",
    "    output_filename=PIPELINE_DEFINITION_FILE)\n",
    "\n",
    "_ = runner.run(\n",
    "    _create_pipeline(\n",
    "        pipeline_name=PIPELINE_NAME,\n",
    "        pipeline_root=PIPELINE_ROOT,\n",
    "        data_root=DATA_ROOT,\n",
    "        endpoint_name=ENDPOINT_NAME,\n",
    "        serving_model_dir=SERVING_MODEL_DIR,\n",
    "        metadata_root=METADATA_ROOT,\n",
    "        region=GOOGLE_CLOUD_REGION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "adef143c-d772-4cf7-a229-f7182e70cf20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineJob created. Resource name: projects/853203979454/locations/us-west1/pipelineJobs/taxicab-pipeline-20230712125702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob created. Resource name: projects/853203979454/locations/us-west1/pipelineJobs/taxicab-pipeline-20230712125702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use this PipelineJob in another session:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:To use this PipelineJob in another session:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline_job = aiplatform.PipelineJob.get('projects/853203979454/locations/us-west1/pipelineJobs/taxicab-pipeline-20230712125702')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:pipeline_job = aiplatform.PipelineJob.get('projects/853203979454/locations/us-west1/pipelineJobs/taxicab-pipeline-20230712125702')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-west1/pipelines/runs/taxicab-pipeline-20230712125702?project=853203979454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-west1/pipelines/runs/taxicab-pipeline-20230712125702?project=853203979454\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform import pipeline_jobs\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "aiplatform.init(project=GOOGLE_CLOUD_PROJECT, location=GOOGLE_CLOUD_REGION)\n",
    "\n",
    "job = pipeline_jobs.PipelineJob(template_path='./taxicab-pipeline_pipeline.json',\n",
    "                                display_name=PIPELINE_NAME)\n",
    "job.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aca994ff-93d1-495c-9c58-ddbf629c7965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_sample(project: str, location: str, endpoint_id: str, instance_dict: Dict):\n",
    "\n",
    "    aiplatform.init(project=project, location=location)\n",
    "\n",
    "    endpoint = aiplatform.Endpoint(endpoint_id)\n",
    "\n",
    "    response = endpoint.explain(instances=[instance_dict], parameters={})\n",
    "\n",
    "    for explanation in response.explanations:\n",
    "        print(\" explanation\")\n",
    "        # Feature attributions.\n",
    "        attributions = explanation.attributions\n",
    "        for attribution in attributions:\n",
    "            print(\"  attribution\")\n",
    "            print(\"   baseline_output_value:\", attribution.baseline_output_value)\n",
    "            print(\"   instance_output_value:\", attribution.instance_output_value)\n",
    "            print(\"   output_display_name:\", attribution.output_display_name)\n",
    "            print(\"   approximation_error:\", attribution.approximation_error)\n",
    "            print(\"   output_name:\", attribution.output_name)\n",
    "            output_index = attribution.output_index\n",
    "            for output_index in output_index:\n",
    "                print(\"   output_index:\", output_index)\n",
    "\n",
    "    for prediction in response.predictions:\n",
    "        print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e3098ac0-b555-4577-8ecd-8959e85c5a51",
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedPrecondition",
     "evalue": "400 Deployed model 8317136961055752192 does not support explanation.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1029\u001b[0m                                       wait_for_ready, compression)\n\u001b[0;32m-> 1030\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    909\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_InactiveRpcError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pytype: disable=not-instantiable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.FAILED_PRECONDITION\n\tdetails = \"Deployed model 8317136961055752192 does not support explanation.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:173.194.203.95:443 {created_time:\"2023-07-12T13:19:05.562832799+00:00\", grpc_status:9, grpc_message:\"Deployed model 8317136961055752192 does not support explanation.\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFailedPrecondition\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_2901/2019032065.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m explain_sample(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'853203979454'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlocation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'us-west1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mendpoint_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'970323409558831104'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0minstance_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/tmp/ipykernel_2901/704281224.py\u001b[0m in \u001b[0;36mexplain_sample\u001b[0;34m(project, location, endpoint_id, instance_dict)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mendpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maiplatform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEndpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minstance_dict\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mexplanation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplanations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/google/cloud/aiplatform/models.py\u001b[0m in \u001b[0;36mexplain\u001b[0;34m(self, instances, parameters, deployed_model_id, timeout)\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1634\u001b[0;31m         explain_response = self._prediction_client.explain(\n\u001b[0m\u001b[1;32m   1635\u001b[0m             \u001b[0mendpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1636\u001b[0m             \u001b[0minstances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/google/cloud/aiplatform_v1/services/prediction_service/client.py\u001b[0m in \u001b[0;36mexplain\u001b[0;34m(self, request, endpoint, instances, parameters, deployed_model_id, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    938\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mFailedPrecondition\u001b[0m: 400 Deployed model 8317136961055752192 does not support explanation."
     ]
    }
   ],
   "source": [
    "explain_sample(\n",
    "    project='853203979454',\n",
    "    location='us-west1',\n",
    "    endpoint_id='970323409558831104',\n",
    "    instance_dict=input_1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27cc1167-03b7-4f63-9327-4399ff4edd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "\n",
    "\n",
    "def predict_tabular_regression(\n",
    "    project: str,\n",
    "    endpoint_id: str,\n",
    "    instance_dict: Dict,\n",
    "    location: str = \"us-west1\",\n",
    "    api_endpoint: str = \"us-west1-aiplatform.googleapis.com\",\n",
    "):\n",
    "    # The AI Platform services require regional API endpoints.\n",
    "    client_options = {\"api_endpoint\": api_endpoint}\n",
    "    # Initialize client that will be used to create and send requests.\n",
    "    # This client only needs to be created once, and can be reused for multiple requests.\n",
    "    client = aiplatform.gapic.PredictionServiceClient(client_options=client_options)\n",
    "    # for more info on the instance schema, please use get_model_sample.py\n",
    "    # and look at the yaml found in instance_schema_uri\n",
    "    instance = json_format.ParseDict(instance_dict, Value())\n",
    "    instances = [instance]\n",
    "    parameters_dict = {}\n",
    "    parameters = json_format.ParseDict(parameters_dict, Value())\n",
    "    endpoint = client.endpoint_path(\n",
    "        project=project, location=location, endpoint=endpoint_id\n",
    "    )\n",
    "    response = client.predict(\n",
    "        endpoint=endpoint, instances=instances, parameters=parameters\n",
    "    )\n",
    "    print(\"response\")\n",
    "    print(\" deployed_model_id:\", response.deployed_model_id)\n",
    "    # See gs://google-cloud-aiplatform/schema/predict/prediction/tabular_regression_1.0.0.yaml for the format of the predictions.\n",
    "    predictions = response.predictions\n",
    "    for prediction in predictions:\n",
    "        print(\" prediction:\", dict(prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "49ce1552-3d0d-4717-906f-fd9ccc5a8505",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1={\n",
    "      \"key\":\"2010-10-19 00:01:17.0000003\",\n",
    "      \"pickup_datetime\":\"2010-10-19 00:01:17 UTC\",\n",
    "      \"pickup_longitude\":-73.94872283935547,\n",
    "      \"pickup_latitude\":40.777488708496094,\n",
    "      \"dropoff_longitude\":-73.94956970214844,\n",
    "      \"dropoff_latitude\":40.814048767089844,\n",
    "      \"passenger_count\":1\n",
    "    }\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "13ef0ed5-0992-4690-a148-ee377f00ee65",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgument",
     "evalue": "400 {\n    \"error\": \"Failed to process element: 0 key: dropoff_latitude of 'instances' list. Error: INVALID_ARGUMENT: JSON object: does not have named input: dropoff_latitude\"\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1029\u001b[0m                                       wait_for_ready, compression)\n\u001b[0;32m-> 1030\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    909\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_InactiveRpcError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pytype: disable=not-instantiable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.INVALID_ARGUMENT\n\tdetails = \"{\n    \"error\": \"Failed to process element: 0 key: dropoff_latitude of 'instances' list. Error: INVALID_ARGUMENT: JSON object: does not have named input: dropoff_latitude\"\n}\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:173.194.203.95:443 {grpc_message:\"{\\n    \\\"error\\\": \\\"Failed to process element: 0 key: dropoff_latitude of \\'instances\\' list. Error: INVALID_ARGUMENT: JSON object: does not have named input: dropoff_latitude\\\"\\n}\", grpc_status:3, created_time:\"2023-07-12T13:19:16.793622431+00:00\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_2901/2614309148.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m predict_tabular_regression(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'853203979454'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mendpoint_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'970323409558831104'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlocation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'us-west1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0minstance_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/tmp/ipykernel_2901/2076953101.py\u001b[0m in \u001b[0;36mpredict_tabular_regression\u001b[0;34m(project, endpoint_id, instance_dict, location, api_endpoint)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendpoint_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     )\n\u001b[0;32m---> 29\u001b[0;31m     response = client.predict(\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mendpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     )\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/google/cloud/aiplatform_v1/services/prediction_service/client.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, request, endpoint, instances, parameters, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgument\u001b[0m: 400 {\n    \"error\": \"Failed to process element: 0 key: dropoff_latitude of 'instances' list. Error: INVALID_ARGUMENT: JSON object: does not have named input: dropoff_latitude\"\n}"
     ]
    }
   ],
   "source": [
    "predict_tabular_regression(\n",
    "    project='853203979454',\n",
    "    endpoint_id='970323409558831104',\n",
    "    location='us-west1',\n",
    "    instance_dict=input_1,\n",
    "    api_endpoint=\"us-west1-aiplatform.googleapis.com\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6753f67f-1521-4629-9dec-6920d3b26672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"key\": \"2010-10-19 00:01:17.0000003\", \"pickup_datetime\": \"2010-10-19 00:01:17 UTC\", \"pickup_longitude\": -73.94872283935547, \"pickup_latitude\": 40.777488708496094, \"dropoff_longitude\": -73.94956970214844, \"dropoff_latitude\": 40.814048767089844, \"passenger_count\": 1}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "features = {\n",
    "    'key': '2010-10-19 00:01:17.0000003',\n",
    "    'pickup_datetime': '2010-10-19 00:01:17 UTC',\n",
    "    'pickup_longitude': -73.94872283935547,\n",
    "    'pickup_latitude': 40.777488708496094,\n",
    "    'dropoff_longitude': -73.94956970214844,\n",
    "    'dropoff_latitude': 40.814048767089844,\n",
    "    'passenger_count': 1\n",
    "}\n",
    "\n",
    "json_data = json.dumps(features)\n",
    "print(json_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "005a21e3-ad2c-4a51-b440-e7816d1eabed",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgument",
     "evalue": "400 {\n    \"error\": \"Failed to process element: 0 key: instances of 'instances' list. Error: INVALID_ARGUMENT: JSON object: does not have named input: instances\"\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1029\u001b[0m                                       wait_for_ready, compression)\n\u001b[0;32m-> 1030\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    909\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_InactiveRpcError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pytype: disable=not-instantiable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.INVALID_ARGUMENT\n\tdetails = \"{\n    \"error\": \"Failed to process element: 0 key: instances of 'instances' list. Error: INVALID_ARGUMENT: JSON object: does not have named input: instances\"\n}\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:173.194.202.95:443 {created_time:\"2023-07-12T14:35:50.129714469+00:00\", grpc_status:3, grpc_message:\"{\\n    \\\"error\\\": \\\"Failed to process element: 0 key: instances of \\'instances\\' list. Error: INVALID_ARGUMENT: JSON object: does not have named input: instances\\\"\\n}\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_2901/1517788811.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m predict_custom_trained_model_sample(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'853203979454'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mendpoint_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'970323409558831104'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlocation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'us-west1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0minstances\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"instances\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"2010-10-19 00:01:17.0000003,2010-10-19 00:01:17 UTC,-73.94872283935547,40.777488708496094, -73.94956970214844,40.814048767089844,1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/tmp/ipykernel_2901/3192180332.py\u001b[0m in \u001b[0;36mpredict_custom_trained_model_sample\u001b[0;34m(project, endpoint_id, instances, location, api_endpoint)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendpoint_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     )\n\u001b[0;32m---> 34\u001b[0;31m     response = client.predict(\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mendpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     )\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/google/cloud/aiplatform_v1/services/prediction_service/client.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, request, endpoint, instances, parameters, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgument\u001b[0m: 400 {\n    \"error\": \"Failed to process element: 0 key: instances of 'instances' list. Error: INVALID_ARGUMENT: JSON object: does not have named input: instances\"\n}"
     ]
    }
   ],
   "source": [
    "predict_custom_trained_model_sample(\n",
    "    project='853203979454',\n",
    "    endpoint_id='970323409558831104',\n",
    "    location='us-west1',\n",
    "    instances= {\"instances\": [\"2010-10-19 00:01:17.0000003,2010-10-19 00:01:17 UTC,-73.94872283935547,40.777488708496094, -73.94956970214844,40.814048767089844,1\"]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "41d4de47-ccc6-4f4b-8e56-9960019e9d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "import urllib\n",
    "\n",
    "import absl\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_analysis as tfma\n",
    "tf.get_logger().propagate = False\n",
    "pp = pprint.PrettyPrinter()\n",
    "\n",
    "from tfx import v1 as tfx\n",
    "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
    "\n",
    "%load_ext tfx.orchestration.experimental.interactive.notebook_extensions.skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1aaa33e4-516f-47ea-9cb7-f7700e6294d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:InteractiveContext pipeline_root argument not provided: using temporary directory /var/tmp/tfx-interactive-2023-07-12T13_28_29.224869-cxhh8kax as root for pipeline outputs.\n",
      "WARNING:absl:InteractiveContext metadata_connection_config not provided: using SQLite ML Metadata database at /var/tmp/tfx-interactive-2023-07-12T13_28_29.224869-cxhh8kax/metadata.sqlite.\n"
     ]
    }
   ],
   "source": [
    "context = InteractiveContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "360acaa0-f05f-4aa8-8eab-7f8724568814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features {\n",
      "  feature {\n",
      "    key: \"dropoff_latitude\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 40.814048767089844\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"dropoff_longitude\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: -73.94956970214844\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"fare_amount\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 11.300000190734863\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"key\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"2010-10-19 00:01:17.0000003\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"passenger_count\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"pickup_datetime\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"2010-10-19 00:01:17 UTC\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"pickup_latitude\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 40.777488708496094\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"pickup_longitude\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: -73.94872283935547\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-12 13:28:29.445007: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "tfrecord_filename = ['./pipeline_taxicab-pipeline_853203979454_taxicab-pipeline-20230628122601_CsvExampleGen_2303745141027897344_examples_Split-train_data_tfrecord-00000-of-00001.gz']\n",
    "\n",
    "\n",
    "dataset = tf.data.TFRecordDataset(tfrecord_filename, compression_type=\"GZIP\")\n",
    "\n",
    "for tfrecord in dataset.take(1):\n",
    "  serialized_example = tfrecord.numpy()\n",
    "  example = tf.train.Example()\n",
    "  example.ParseFromString(serialized_example)\n",
    "  pp.pprint(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d459a78-a26a-48b4-bde5-5c6e3fc5c6f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgument",
     "evalue": "400 {\n    \"error\": \"Failed to process element: 0 key: dropoff_latitude of 'instances' list. Error: Invalid argument: JSON object: does not have named input: dropoff_latitude\"\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1029\u001b[0m                                       wait_for_ready, compression)\n\u001b[0;32m-> 1030\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    909\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_InactiveRpcError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pytype: disable=not-instantiable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.INVALID_ARGUMENT\n\tdetails = \"{\n    \"error\": \"Failed to process element: 0 key: dropoff_latitude of 'instances' list. Error: Invalid argument: JSON object: does not have named input: dropoff_latitude\"\n}\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:74.125.197.95:443 {created_time:\"2023-07-12T09:07:34.444882587+00:00\", grpc_status:3, grpc_message:\"{\\n    \\\"error\\\": \\\"Failed to process element: 0 key: dropoff_latitude of \\'instances\\' list. Error: Invalid argument: JSON object: does not have named input: dropoff_latitude\\\"\\n}\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_2935/2333195210.py\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m }\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/google/cloud/aiplatform/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, instances, parameters, timeout, use_raw_predict)\u001b[0m\n\u001b[1;32m   1539\u001b[0m             )\n\u001b[1;32m   1540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1541\u001b[0;31m             prediction_response = self._prediction_client.predict(\n\u001b[0m\u001b[1;32m   1542\u001b[0m                 \u001b[0mendpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m                 \u001b[0minstances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/google/cloud/aiplatform_v1/services/prediction_service/client.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, request, endpoint, instances, parameters, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgument\u001b[0m: 400 {\n    \"error\": \"Failed to process element: 0 key: dropoff_latitude of 'instances' list. Error: Invalid argument: JSON object: does not have named input: dropoff_latitude\"\n}"
     ]
    }
   ],
   "source": [
    "instance={\n",
    "    'key' : '2010-10-19 00:01:17.0000003',\n",
    "    'pickup_datetime': '2010-10-19 00:01:17 UTC',\n",
    "    'pickup_longitude': -73.94872283935547,\n",
    "    'pickup_latitude': 40.777488708496094,\n",
    "    'dropoff_longitude': -73.94956970214844,\n",
    "    'dropoff_latitude' : 40.814048767089844,\n",
    "    'passenger_count': 1,\n",
    "   \n",
    "}\n",
    "\n",
    "response=endpoint.predict([instance])\n",
    "\n",
    "print(response)\n",
    "print('Value predicted for the first sample: ', response.predictions[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f7a6c2b6-963c-42f4-ae55-7ccc82737e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\n",
    "from tfx.orchestration import pipeline\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "from apache_beam.runners import DataflowRunner\n",
    "from tfx.orchestration import metadata\n",
    "from ml_metadata.proto import metadata_store_pb2\n",
    "from typing import Optional, Text, List, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ddc30901-bf17-4bb2-904e-93e3b634d35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_NAME = 'dataflow-pipeline'\n",
    "PIPELINE_ROOT = 'gs://gcp-ml-pipeline/pipeline/dataflow-pipeline'\n",
    "DATA_ROOT = 'gs://gcp-ml-pipeline/pipeline/taxicab-pipeline/data'\n",
    "SERVING_MODEL_DIR = 'gs://gcp-ml-pipeline/pipeline/dataflow-pipeline/serving_model'\n",
    "METADATA_ROOT = './dataflow-pipeline/metadata/metadata.db'\n",
    "LABEL_NAME = 'fare_amount'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4e3a3591-d445-41e7-9f12-d1027b295887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_pipeline(pipeline_name: str, pipeline_root: str, data_root: str,\n",
    "                     serving_model_dir: str,  metadata_connection_config: Optional[\n",
    "        metadata_store_pb2.ConnectionConfig] = None,\n",
    "                     ) -> tfx.dsl.Pipeline:\n",
    "    \n",
    "    output = proto.Output(\n",
    "             split_config=example_gen_pb2.SplitConfig(splits=[\n",
    "                 proto.SplitConfig.Split(name='train', hash_buckets=3),\n",
    "                 proto.SplitConfig.Split(name='eval', hash_buckets=1)\n",
    "             ]))\n",
    "\n",
    "    example_gen = CsvExampleGen(input_base='gs://gcp-ml-pipeline/pipeline/taxicab-pipeline/data', output_config=output)\n",
    "    print(example_gen)\n",
    "    \n",
    "    stats_options = tfdv.StatsOptions(label_feature=LABEL_NAME)\n",
    "    statistics_gen = StatisticsGen(examples=example_gen.outputs['examples'], stats_options=stats_options)\n",
    "    \n",
    "    schema_gen = SchemaGen(\n",
    "        statistics=statistics_gen.outputs['statistics'], infer_feature_shape=True)\n",
    "    \n",
    "    transform = Transform(examples = example_gen.outputs['examples'], schema = schema_gen.outputs['schema'], module_file='./preprocessing_fn.py', materialize=True)  \n",
    "    \n",
    "    tuner = Tuner(\n",
    "    module_file='./tuner.py',\n",
    "    examples=transform.outputs['transformed_examples'],\n",
    "    transform_graph = transform.outputs['transform_graph'],\n",
    "    schema=transform.outputs['post_transform_schema'],\n",
    "    train_args=proto.TrainArgs(splits=['train'], num_steps=2500),\n",
    "    eval_args=proto.EvalArgs(splits=['eval'], num_steps=50),\n",
    "    # tune_args=tune_args\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "    module_file='./model.py',\n",
    "    examples=transform.outputs['transformed_examples'],\n",
    "    transform_graph = transform.outputs['transform_graph'],\n",
    "    schema=transform.outputs['post_transform_schema'],\n",
    "    hyperparameters = tuner.outputs['best_hyperparameters'],\n",
    "    train_args=proto.TrainArgs(splits=['train'], num_steps=7500),\n",
    "    eval_args=proto.EvalArgs(splits=['eval'], num_steps=2500))\n",
    "    \n",
    "    example_validator = ExampleValidator(statistics=statistics_gen.outputs['statistics'], schema=schema_gen.outputs['schema'])\n",
    "    \n",
    "    '''infra_validator = tfx.components.InfraValidator(\n",
    "      model=trainer.outputs['model'],\n",
    "      examples=example_gen.outputs['examples'],\n",
    "      serving_spec=tfx.proto.ServingSpec(\n",
    "          # TODO(b/244254788): Roll back to the 'latest' tag.\n",
    "          tensorflow_serving=tfx.proto.TensorFlowServing(tags=['latest']),\n",
    "          local_docker=tfx.proto.LocalDockerConfig()\n",
    "      ),\n",
    "      request_spec=tfx.proto.RequestSpec(\n",
    "          tensorflow_serving=tfx.proto.TensorFlowServingRequestSpec(),\n",
    "          # If this flag is set, InfraValidator will produce a model with\n",
    "          # warmup requests (in its outputs['blessing']).\n",
    "          make_warmup=True),\n",
    "      validation_spec=tfx.proto.ValidationSpec(\n",
    "        # How much time to wait for model to load before automatically making\n",
    "        # validation fail.\n",
    "        max_loading_time_seconds=60,\n",
    "        # How many times to retry if infra validation fails.\n",
    "        num_tries=3\n",
    "        )\n",
    "    )'''\n",
    "    \n",
    "    model_resolver = tfx.dsl.Resolver(\n",
    "      strategy_class=tfx.dsl.experimental.LatestBlessedModelStrategy,\n",
    "      model=tfx.dsl.Channel(type=tfx.types.standard_artifacts.Model),\n",
    "      model_blessing=tfx.dsl.Channel(\n",
    "          type=tfx.types.standard_artifacts.ModelBlessing))\n",
    "\n",
    "    eval_config = tfma.EvalConfig(\n",
    "          model_specs=[\n",
    "              tfma.ModelSpec(signature_name='serving_default', label_key=LABEL_NAME, preprocessing_function_names=['transform_features'])] ,\n",
    "          slicing_specs=[\n",
    "              tfma.SlicingSpec(),\n",
    "              # tfma.SlicingSpec(feature_keys=['trip_start_hour'])\n",
    "          ],\n",
    "          metrics_specs=[\n",
    "              tfma.MetricsSpec(\n",
    "                  thresholds={\n",
    "                      'mse':\n",
    "                          tfma.MetricThreshold(\n",
    "                              value_threshold=tfma.GenericValueThreshold(\n",
    "                                  upper_bound={'value': 2e2}),\n",
    "                              change_threshold=tfma.GenericChangeThreshold(\n",
    "                                  direction=tfma.MetricDirection.LOWER_IS_BETTER,\n",
    "                                  absolute={'value': 1e-1}))\n",
    "                  }\n",
    "          )]\n",
    "    )\n",
    "\n",
    "\n",
    "    evaluator = tfx.components.Evaluator(\n",
    "        examples=example_gen.outputs['examples'],\n",
    "        model=trainer.outputs['model'],\n",
    "        baseline_model=model_resolver.outputs['model'],\n",
    "        eval_config=eval_config\n",
    "    )\n",
    "    # }}}\n",
    "    # {{{ Pusher\n",
    "    pusher = Pusher(\n",
    "        model=trainer.outputs['model'],\n",
    "        model_blessing=evaluator.outputs['blessing'],\n",
    "        #infra_blessing=infra_validator.outputs['blessing'],\n",
    "        push_destination=tfx.proto.PushDestination(\n",
    "        filesystem=tfx.proto.PushDestination.Filesystem(\n",
    "        base_directory=serving_model_dir)\n",
    "      )\n",
    "    )\n",
    "\n",
    "    components = [\n",
    "              example_gen,\n",
    "              statistics_gen,\n",
    "              schema_gen,\n",
    "              transform,\n",
    "              trainer,\n",
    "              example_validator,\n",
    "              tuner,\n",
    "              evaluator,\n",
    "              pusher,\n",
    "              model_resolver,\n",
    "        ]\n",
    "        # }}}\n",
    "        # {{{ Pipeline Definition\n",
    "    pipeline_name=pipeline_name\n",
    "    pipeline_root=pipeline_root\n",
    "    \n",
    "    beam_pipeline_args = [\n",
    "    '--runner=DataflowRunner',\n",
    "    '--project=itp-ml-sndbx',\n",
    "    '--region=us-west1',\n",
    "    '--temp_location=gs://gcp-ml-pipeline/pipeline/dataflow-pipeline/tmp',\n",
    "]  \n",
    "    \n",
    "    pipeline_t = tfx.dsl.Pipeline(\n",
    "              pipeline_name=pipeline_name,\n",
    "              pipeline_root=pipeline_root,\n",
    "              metadata_connection_config=metadata_connection_config,\n",
    "              components=components,\n",
    "              beam_pipeline_args=beam_pipeline_args,\n",
    "              enable_cache=True)\n",
    "        \n",
    "    return pipeline_t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9d825c4f-ce47-45e5-af55-8460759e5094",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
      "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
      "INFO:absl:Excluding no splits because exclude_splits is not set.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CsvExampleGen(spec: <tfx.types.standard_component_specs.FileBasedExampleGenSpec object at 0x7ff47fcce130>, executor_spec: <tfx.dsl.components.base.executor_spec.BeamExecutorSpec object at 0x7ff49c143e80>, driver_class: <class 'tfx.components.example_gen.driver.FileBasedDriver'>, component_id: CsvExampleGen, inputs: {}, outputs: {'examples': OutputChannel(artifact_type=Examples, producer_component_id=CsvExampleGen, output_key=examples, additional_properties={}, additional_custom_properties={}, _input_trigger=None})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Generating ephemeral wheel package for '/home/jupyter/taxicab-pipeline/preprocessing_fn.py' (including modules: ['model', 'tfx-client', 'tuner', 'transparency', 'preprocessing_fn']).\n",
      "INFO:absl:User module package has hash fingerprint version a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7.\n",
      "INFO:absl:Executing: ['/opt/conda/bin/python', '/var/tmp/tmp0vxdcp17/_tfx_generated_setup.py', 'bdist_wheel', '--bdist-dir', '/var/tmp/tmpr5xrpiq8', '--dist-dir', '/var/tmp/tmp9xuaqkss']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "copying model.py -> build/lib\n",
      "copying tfx-client.py -> build/lib\n",
      "copying tuner.py -> build/lib\n",
      "copying transparency.py -> build/lib\n",
      "copying preprocessing_fn.py -> build/lib\n",
      "installing to /var/tmp/tmpr5xrpiq8\n",
      "running install\n",
      "running install_lib\n",
      "copying build/lib/model.py -> /var/tmp/tmpr5xrpiq8\n",
      "copying build/lib/tuner.py -> /var/tmp/tmpr5xrpiq8\n",
      "copying build/lib/preprocessing_fn.py -> /var/tmp/tmpr5xrpiq8\n",
      "copying build/lib/tfx-client.py -> /var/tmp/tmpr5xrpiq8\n",
      "copying build/lib/transparency.py -> /var/tmp/tmpr5xrpiq8\n",
      "running install_egg_info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "!!\n",
      "\n",
      "        ********************************************************************************\n",
      "        Please avoid running ``setup.py`` directly.\n",
      "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
      "        other standards-based tools.\n",
      "\n",
      "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "        ********************************************************************************\n",
      "\n",
      "!!\n",
      "  self.initialize_options()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running egg_info\n",
      "creating tfx_user_code_Transform.egg-info\n",
      "writing tfx_user_code_Transform.egg-info/PKG-INFO\n",
      "writing dependency_links to tfx_user_code_Transform.egg-info/dependency_links.txt\n",
      "writing top-level names to tfx_user_code_Transform.egg-info/top_level.txt\n",
      "writing manifest file 'tfx_user_code_Transform.egg-info/SOURCES.txt'\n",
      "reading manifest file 'tfx_user_code_Transform.egg-info/SOURCES.txt'\n",
      "writing manifest file 'tfx_user_code_Transform.egg-info/SOURCES.txt'\n",
      "Copying tfx_user_code_Transform.egg-info to /var/tmp/tmpr5xrpiq8/tfx_user_code_Transform-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7-py3.9.egg-info\n",
      "running install_scripts\n",
      "creating /var/tmp/tmpr5xrpiq8/tfx_user_code_Transform-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7.dist-info/WHEEL\n",
      "creating '/var/tmp/tmp9xuaqkss/tfx_user_code_Transform-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7-py3-none-any.whl' and adding '/var/tmp/tmpr5xrpiq8' to it\n",
      "adding 'model.py'\n",
      "adding 'preprocessing_fn.py'\n",
      "adding 'tfx-client.py'\n",
      "adding 'transparency.py'\n",
      "adding 'tuner.py'\n",
      "adding 'tfx_user_code_Transform-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7.dist-info/METADATA'\n",
      "adding 'tfx_user_code_Transform-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7.dist-info/WHEEL'\n",
      "adding 'tfx_user_code_Transform-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7.dist-info/top_level.txt'\n",
      "adding 'tfx_user_code_Transform-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7.dist-info/RECORD'\n",
      "removing /var/tmp/tmpr5xrpiq8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Successfully built user code wheel distribution at 'gs://gcp-ml-pipeline/pipeline/dataflow-pipeline/_wheels/tfx_user_code_Transform-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7-py3-none-any.whl'; target user module is 'preprocessing_fn'.\n",
      "INFO:absl:Full user module path is 'preprocessing_fn@gs://gcp-ml-pipeline/pipeline/dataflow-pipeline/_wheels/tfx_user_code_Transform-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7-py3-none-any.whl'\n",
      "INFO:absl:Generating ephemeral wheel package for '/home/jupyter/taxicab-pipeline/tuner.py' (including modules: ['model', 'tfx-client', 'tuner', 'transparency', 'preprocessing_fn']).\n",
      "INFO:absl:User module package has hash fingerprint version a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7.\n",
      "INFO:absl:Executing: ['/opt/conda/bin/python', '/var/tmp/tmp2gigppet/_tfx_generated_setup.py', 'bdist_wheel', '--bdist-dir', '/var/tmp/tmpw6grazrr', '--dist-dir', '/var/tmp/tmp0t4pxebt']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "copying model.py -> build/lib\n",
      "copying tfx-client.py -> build/lib\n",
      "copying tuner.py -> build/lib\n",
      "copying transparency.py -> build/lib\n",
      "copying preprocessing_fn.py -> build/lib\n",
      "installing to /var/tmp/tmpw6grazrr\n",
      "running install\n",
      "running install_lib\n",
      "copying build/lib/model.py -> /var/tmp/tmpw6grazrr\n",
      "copying build/lib/tuner.py -> /var/tmp/tmpw6grazrr\n",
      "copying build/lib/preprocessing_fn.py -> /var/tmp/tmpw6grazrr\n",
      "copying build/lib/tfx-client.py -> /var/tmp/tmpw6grazrr\n",
      "copying build/lib/transparency.py -> /var/tmp/tmpw6grazrr\n",
      "running install_egg_info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "!!\n",
      "\n",
      "        ********************************************************************************\n",
      "        Please avoid running ``setup.py`` directly.\n",
      "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
      "        other standards-based tools.\n",
      "\n",
      "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "        ********************************************************************************\n",
      "\n",
      "!!\n",
      "  self.initialize_options()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running egg_info\n",
      "creating tfx_user_code_Tuner.egg-info\n",
      "writing tfx_user_code_Tuner.egg-info/PKG-INFO\n",
      "writing dependency_links to tfx_user_code_Tuner.egg-info/dependency_links.txt\n",
      "writing top-level names to tfx_user_code_Tuner.egg-info/top_level.txt\n",
      "writing manifest file 'tfx_user_code_Tuner.egg-info/SOURCES.txt'\n",
      "reading manifest file 'tfx_user_code_Tuner.egg-info/SOURCES.txt'\n",
      "writing manifest file 'tfx_user_code_Tuner.egg-info/SOURCES.txt'\n",
      "Copying tfx_user_code_Tuner.egg-info to /var/tmp/tmpw6grazrr/tfx_user_code_Tuner-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7-py3.9.egg-info\n",
      "running install_scripts\n",
      "creating /var/tmp/tmpw6grazrr/tfx_user_code_Tuner-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7.dist-info/WHEEL\n",
      "creating '/var/tmp/tmp0t4pxebt/tfx_user_code_Tuner-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7-py3-none-any.whl' and adding '/var/tmp/tmpw6grazrr' to it\n",
      "adding 'model.py'\n",
      "adding 'preprocessing_fn.py'\n",
      "adding 'tfx-client.py'\n",
      "adding 'transparency.py'\n",
      "adding 'tuner.py'\n",
      "adding 'tfx_user_code_Tuner-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7.dist-info/METADATA'\n",
      "adding 'tfx_user_code_Tuner-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7.dist-info/WHEEL'\n",
      "adding 'tfx_user_code_Tuner-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7.dist-info/top_level.txt'\n",
      "adding 'tfx_user_code_Tuner-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7.dist-info/RECORD'\n",
      "removing /var/tmp/tmpw6grazrr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Successfully built user code wheel distribution at 'gs://gcp-ml-pipeline/pipeline/dataflow-pipeline/_wheels/tfx_user_code_Tuner-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7-py3-none-any.whl'; target user module is 'tuner'.\n",
      "INFO:absl:Full user module path is 'tuner@gs://gcp-ml-pipeline/pipeline/dataflow-pipeline/_wheels/tfx_user_code_Tuner-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7-py3-none-any.whl'\n",
      "INFO:absl:Generating ephemeral wheel package for '/home/jupyter/taxicab-pipeline/model.py' (including modules: ['model', 'tfx-client', 'tuner', 'transparency', 'preprocessing_fn']).\n",
      "INFO:absl:User module package has hash fingerprint version a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7.\n",
      "INFO:absl:Executing: ['/opt/conda/bin/python', '/var/tmp/tmp5mns8y8q/_tfx_generated_setup.py', 'bdist_wheel', '--bdist-dir', '/var/tmp/tmpmubgogrw', '--dist-dir', '/var/tmp/tmpzutaw0yd']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "copying model.py -> build/lib\n",
      "copying tfx-client.py -> build/lib\n",
      "copying tuner.py -> build/lib\n",
      "copying transparency.py -> build/lib\n",
      "copying preprocessing_fn.py -> build/lib\n",
      "installing to /var/tmp/tmpmubgogrw\n",
      "running install\n",
      "running install_lib\n",
      "copying build/lib/model.py -> /var/tmp/tmpmubgogrw\n",
      "copying build/lib/tuner.py -> /var/tmp/tmpmubgogrw\n",
      "copying build/lib/preprocessing_fn.py -> /var/tmp/tmpmubgogrw\n",
      "copying build/lib/tfx-client.py -> /var/tmp/tmpmubgogrw\n",
      "copying build/lib/transparency.py -> /var/tmp/tmpmubgogrw\n",
      "running install_egg_info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "!!\n",
      "\n",
      "        ********************************************************************************\n",
      "        Please avoid running ``setup.py`` directly.\n",
      "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
      "        other standards-based tools.\n",
      "\n",
      "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "        ********************************************************************************\n",
      "\n",
      "!!\n",
      "  self.initialize_options()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running egg_info\n",
      "creating tfx_user_code_Trainer.egg-info\n",
      "writing tfx_user_code_Trainer.egg-info/PKG-INFO\n",
      "writing dependency_links to tfx_user_code_Trainer.egg-info/dependency_links.txt\n",
      "writing top-level names to tfx_user_code_Trainer.egg-info/top_level.txt\n",
      "writing manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "reading manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "writing manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "Copying tfx_user_code_Trainer.egg-info to /var/tmp/tmpmubgogrw/tfx_user_code_Trainer-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7-py3.9.egg-info\n",
      "running install_scripts\n",
      "creating /var/tmp/tmpmubgogrw/tfx_user_code_Trainer-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7.dist-info/WHEEL\n",
      "creating '/var/tmp/tmpzutaw0yd/tfx_user_code_Trainer-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7-py3-none-any.whl' and adding '/var/tmp/tmpmubgogrw' to it\n",
      "adding 'model.py'\n",
      "adding 'preprocessing_fn.py'\n",
      "adding 'tfx-client.py'\n",
      "adding 'transparency.py'\n",
      "adding 'tuner.py'\n",
      "adding 'tfx_user_code_Trainer-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7.dist-info/METADATA'\n",
      "adding 'tfx_user_code_Trainer-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7.dist-info/WHEEL'\n",
      "adding 'tfx_user_code_Trainer-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7.dist-info/top_level.txt'\n",
      "adding 'tfx_user_code_Trainer-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7.dist-info/RECORD'\n",
      "removing /var/tmp/tmpmubgogrw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Successfully built user code wheel distribution at 'gs://gcp-ml-pipeline/pipeline/dataflow-pipeline/_wheels/tfx_user_code_Trainer-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7-py3-none-any.whl'; target user module is 'model'.\n",
      "INFO:absl:Full user module path is 'model@gs://gcp-ml-pipeline/pipeline/dataflow-pipeline/_wheels/tfx_user_code_Trainer-0.0+a934c052176f163d3dab67799ea8d35eaba6c4a2c448e43701a7efbd323252e7-py3-none-any.whl'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineJob created. Resource name: projects/853203979454/locations/us-west1/pipelineJobs/dataflow-pipeline-20230712001655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob created. Resource name: projects/853203979454/locations/us-west1/pipelineJobs/dataflow-pipeline-20230712001655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use this PipelineJob in another session:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:To use this PipelineJob in another session:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline_job = aiplatform.PipelineJob.get('projects/853203979454/locations/us-west1/pipelineJobs/dataflow-pipeline-20230712001655')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:pipeline_job = aiplatform.PipelineJob.get('projects/853203979454/locations/us-west1/pipelineJobs/dataflow-pipeline-20230712001655')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-west1/pipelines/runs/dataflow-pipeline-20230712001655?project=853203979454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-west1/pipelines/runs/dataflow-pipeline-20230712001655?project=853203979454\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform import pipeline_jobs\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "PIPELINE_DEFINITION_FILE = './dataflow-pipeline.json'\n",
    "\n",
    "runner = tfx.orchestration.experimental.KubeflowV2DagRunner(\n",
    "    config=tfx.orchestration.experimental.KubeflowV2DagRunnerConfig(),\n",
    "    output_filename=PIPELINE_DEFINITION_FILE)\n",
    "\n",
    "_=runner.run(\n",
    "    pipeline=_create_pipeline(\n",
    "        pipeline_name=PIPELINE_NAME,\n",
    "        pipeline_root=PIPELINE_ROOT,\n",
    "        data_root=DATA_ROOT,\n",
    "        serving_model_dir=SERVING_MODEL_DIR,\n",
    "        metadata_connection_config=metadata.sqlite_metadata_connection_config(METADATA_ROOT)))\n",
    "    \n",
    "\n",
    "aiplatform.init(project=GOOGLE_CLOUD_PROJECT, location=GOOGLE_CLOUD_REGION)\n",
    "\n",
    "job = pipeline_jobs.PipelineJob(template_path='./dataflow-pipeline.json',\n",
    "                                display_name=PIPELINE_NAME)\n",
    "job.submit()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ace93d-5430-4e0a-8001-42525b6893a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
